{
  "reward": [
    4.43044273853302
  ],
  "kl_divergence": [
    2.484749907851219
  ],
  "policy_loss": [
    -0.011315622210502625
  ],
  "entropy": [
    2.4475352271515876
  ],
  "total_loss": [
    0.08844652223750017
  ],
  "time_per_iteration": [
    1.624375568151474
  ]
}